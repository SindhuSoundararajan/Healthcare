{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwi9mzFPPDv7"
   },
   "source": [
    "# Identifying Entities in Healthcare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wwzoMzrUDtr"
   },
   "source": [
    "##Workspace set up: Import and Install useful packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T4hxafMCE1nn",
    "outputId": "e1326ee6-8d32-421c-f0d1-b6dec39f6443"
   },
   "outputs": [],
   "source": [
    "!pip install pycrf\n",
    "!pip install sklearn-crfsuite\n",
    "!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz\n",
    "    \n",
    "import spacy\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "#import en-core_web_sm\n",
    "\n",
    "model = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bE9Hwb3AUHwG"
   },
   "source": [
    "##Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bz6czVx9R6WJ"
   },
   "outputs": [],
   "source": [
    "def process_file(filename):\n",
    "  input_file = open(filename, 'r')\n",
    "  file_content = input_file.readlines() \n",
    "  input_file.close()\n",
    "\n",
    "  out_lines = [] #To store list of sequences (sentences or labels)\n",
    "\n",
    "  line_content = \"\"\n",
    "\n",
    "  for word in file_content:\n",
    "    word = word.strip() \n",
    "    if word == \"\": # If empty line, add the current sequence to out_lines\n",
    "      out_lines.append(line_content)\n",
    "      line_content = \"\"; # re-initialize\n",
    "    else:\n",
    "      if line_content: #if non-empty, add new word after space\n",
    "        line_content += \" \"+word\n",
    "      else:\n",
    "        line_content = word # first word, no space required\n",
    "\n",
    "  return out_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TE31q8yxVdU-"
   },
   "outputs": [],
   "source": [
    "train_sentences = process_file('train_sent')\n",
    "train_labels = process_file('train_label')\n",
    "test_sentences = process_file('test_sent')\n",
    "test_labels = process_file('test_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k4gdPBHwLdNX",
    "outputId": "bf32ffe6-4161-450f-9f5d-79b78166254a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: All live births > or = 23 weeks at the University of Vermont in 1995 ( n = 2395 ) were retrospectively analyzed for delivery route , indication for cesarean , gestational age , parity , and practice group ( to reflect risk status )\n",
      "Labels: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O \n",
      "\n",
      "\n",
      "Sentence: The total cesarean rate was 14.4 % ( 344 of 2395 ) , and the primary rate was 11.4 % ( 244 of 2144 )\n",
      "Labels: O O O O O O O O O O O O O O O O O O O O O O O O O \n",
      "\n",
      "\n",
      "Sentence: Abnormal presentation was the most common indication ( 25.6 % , 88 of 344 )\n",
      "Labels: O O O O O O O O O O O O O O O \n",
      "\n",
      "\n",
      "Sentence: The `` corrected '' cesarean rate ( maternal-fetal medicine and transported patients excluded ) was 12.4 % ( 273 of 2194 ) , and the `` corrected '' primary rate was 9.6 % ( 190 of 1975 )\n",
      "Labels: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O \n",
      "\n",
      "\n",
      "Sentence: Arrest of dilation was the most common indication in both `` corrected '' subgroups ( 23.4 and 24.6 % , respectively )\n",
      "Labels: O O O O O O O O O O O O O O O O O O O O O O \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the 5 sentences from the processed dataset\n",
    "for i in range(5):\n",
    "  print(\"Sentence:\", train_sentences[i])\n",
    "  print(\"Labels:\", train_labels[i], \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urCxIOBTMBwG"
   },
   "source": [
    "### Count the number of sentences in the processed train and test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zwa18H_IMFXV",
    "outputId": "36614b78-1827-4a48-d388-79b0d14be32d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of lines in train_sentences: 2599\n",
      "No. of lines in test_sentences: 1056\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of lines in train_sentences:\", len(train_sentences))\n",
    "print(\"No. of lines in test_sentences:\", len(test_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jjg2DK7hLcO_"
   },
   "source": [
    "### Count the number of lines of labels in the processed train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "unXoD2bWLPZD",
    "outputId": "7b47b33b-0fad-448f-88f9-89f521bf2c70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of lines in train_labels: 2599\n",
      "No. of lines in test_labels: 1056\n"
     ]
    }
   ],
   "source": [
    "# The lengths of the four variables should match the below output\n",
    "print(\"No. of lines in train_labels:\", len(train_labels))\n",
    "print(\"No. of lines in test_labels:\", len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list to hold all the tokens which are either NOUN or PROPER NOUN\n",
    "noun_propn_tokens_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "7w8nJSPlZqjw"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10908/3826707442.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_sentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprocessed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Process each sentence by spacy model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprocessed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m       \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'NOUN'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'PROPN'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#check if the token is a noun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for sentences in (train_sentences, test_sentences):\n",
    "  for sentence in sentences:\n",
    "    processed = model(sentence) # Process each sentence by spacy model\n",
    "    for token in processed:\n",
    "      if(token.pos_ == 'NOUN' or token.pos_ == 'PROPN'): #check if the token is a noun\n",
    "         noun_propn_tokens_list.append(each_token.text); #increase its frequency if it is noun\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YGpfOK7Mk3X"
   },
   "source": [
    "### Extract those tokens which have NOUN or PROPN as their PoS tag and find their frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sindh\\AppData\\Local\\Temp/ipykernel_10908/1296731188.py:1: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  df_noun_propn = pd.Series(noun_propn_tokens_list)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noun_propn = pd.Series(noun_propn_tokens_list)\n",
    "df_noun_propn.value_counts().sort_values(ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SQG8wRxMo6A"
   },
   "source": [
    "### Print the top 25 most common tokens with NOUN or PROPN PoS tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6p6rItAX_Y4a"
   },
   "source": [
    "The output can be tested if the top 25 most common concepts and their frequencies match the following output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aS6P1Gog3JMf"
   },
   "outputs": [],
   "source": [
    "# Let's define the features to get the feature value for one word.\n",
    "\n",
    "def getFeaturesForOneWord(sentence, pos, pos_tags):\n",
    "  word = sentence[pos]\n",
    "\n",
    "  #Define 12 features with PoS tag as one of the features\n",
    "  features = [\n",
    "    'word.lower=' + word.lower(), # serves as word id\n",
    "    'word[-3:]=' + word[-3:],     # last three characters\n",
    "    'word[-2:]=' + word[-2:],     # last two characters\n",
    "    'word.isupper=%s' % word.isupper(),  # is the word in all uppercase\n",
    "    'word.isdigit=%s' % word.isdigit(),  # is the word a number\n",
    "    'word.startsWithCapital=%s' % word[0].isupper(), # is the word starting with a capital letter\n",
    "    'word.pos=' + pos_tags[pos]\n",
    "  ]\n",
    "\n",
    "  #Use the previous word also while defining features\n",
    "  if(pos > 0):\n",
    "    prev_word = sentence[pos-1]\n",
    "    features.extend([\n",
    "    'prev_word.lower=' + prev_word.lower(), \n",
    "    'prev_word.isupper=%s' % prev_word.isupper(),\n",
    "    'prev_word.isdigit=%s' % prev_word.isdigit(),\n",
    "    'prev_word.startsWithCapital=%s' % prev_word[0].isupper(),\n",
    "    'prev_word.pos=' + pos_tags[pos-1]\n",
    "  ])\n",
    "  # Mark the begining and the end words of a sentence correctly in the form of features.\n",
    "  else:\n",
    "    features.append('BEG') # feature to track begin of sentence \n",
    "\n",
    "  if(pos == len(sentence)-1):\n",
    "    features.append('END') # feature to track end of sentence\n",
    "\n",
    "  return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haBEOsZGKhb9"
   },
   "source": [
    "## Getting the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fwb8YUdlNcG1"
   },
   "source": [
    "### Define a function to get the features for a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "emBIm5uK7vtK"
   },
   "outputs": [],
   "source": [
    "# Define a function to get features for a sentence using the 'getFeaturesForOneWord' function.\n",
    "def getFeaturesForOneSentence(sentence):\n",
    "  \n",
    "  processed = model(sentence) #spacy is applied to sentence\n",
    "  \n",
    "  pos_tags = [] #correctly identify pos tags\n",
    "  for token in processed:\n",
    "    pos_tags.append(token.pos_)\n",
    "\n",
    "  sentence_list = sentence.split() # List of words in sentence\n",
    "  \n",
    "  #Correctly calling getFeaturesForOneWord defined above\n",
    "  return [getFeaturesForOneWord(sentence_list, pos, pos_tags) for pos in range(len(sentence_list))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7fs-B8CNein"
   },
   "source": [
    "### Define a function to get the labels of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tiA-A_ws8I8-"
   },
   "outputs": [],
   "source": [
    "# Define a function to get the labels for a sentence.\n",
    "def getLabelsInListForOneSentence(labels):\n",
    "  return labels.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Nuz-MjW8LWm"
   },
   "outputs": [],
   "source": [
    "X_train = [getFeaturesForOneSentence(sentence) for sentence in train_sentences]\n",
    "X_test = [getFeaturesForOneSentence(sentence) for sentence in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrzLkWs0Nvx4"
   },
   "outputs": [],
   "source": [
    "Y_train = [getLabelsInListForOneSentence(labels) for labels in train_labels]\n",
    "Y_test = [getLabelsInListForOneSentence(labels) for labels in test_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrIAz8gqN_Js"
   },
   "source": [
    "## Build the CRF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k2oGSiqQ8Otd",
    "outputId": "3190d3aa-d7e4-4faa-8044-4e723b353ce7"
   },
   "outputs": [],
   "source": [
    "# Build the CRF model.\n",
    "\n",
    "# Calling CRF \n",
    "crf = sklearn_crfsuite.CRF(max_iterations=100)\n",
    "\n",
    "# Check that only X_train and Y_train are passed\n",
    "crf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VPFrPZJOJMq"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_sDJs1n8-sI"
   },
   "outputs": [],
   "source": [
    "Y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIneYrqZOUiJ"
   },
   "source": [
    "### Calculate the f1 score using the actual labels and the predicted labels of the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lr_JNIgrOTcr",
    "outputId": "ec5511a3-aebc-4104-a4fc-36aacb621852"
   },
   "outputs": [],
   "source": [
    "metrics.flat_f1_score(Y_test, Y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty dictionary to hold diseases and their corresponding treatments\n",
    "dict_D = dict()\n",
    "\n",
    "for i in range(len(Y_pred)):\n",
    "    val = Y_pred[i]\n",
    "    \n",
    "    # Empty strings to store the values of Diseases and Treatments\n",
    "    Diseases = \"\"\n",
    "    Treatments = \"\"\n",
    "    for j in range(len(val)):\n",
    "        if val[j] == 'D': # If label is D, it indicates a Disease \n",
    "            Diseases += test_sentences[i].split()[j] + \" \"\n",
    "        elif val[j] == 'T': # If label is T, it indicates a Treatment\n",
    "            Treatments += test_sentences[i].split()[j] + \" \"\n",
    "            \n",
    "    # Removes any extra whitespaces to either end of the string\n",
    "    Diseases = Diseases.lstrip().rstrip()\n",
    "    Treatments = Treatments.lstrip().rstrip()\n",
    "\n",
    "    # If Diseases and Treatments are blank, ignore them\n",
    "    # If Disease is not present in Dictionary, add it along with the corresponding treatment\n",
    "    # If Disease is present in the Dictionary, append the treatments for that diseases with existing\n",
    "    # treatments\n",
    "    if Diseases != \"\" and Treatments != \"\":\n",
    "        if Diseases in dict_D.keys():\n",
    "            treat_out = list(dict_D[Diseases])\n",
    "            treat_out.append(Treatments)\n",
    "            dict_D[Diseases] = treat_out\n",
    "        elif Diseases not in dict_D.keys():\n",
    "            dict_D[Diseases] = Treatments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvTodSY5OfZ9"
   },
   "source": [
    "### Predict the treatment for the disease name: 'hereditary retinoblastoma'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9GaGh-dVzix"
   },
   "source": [
    "This is just to check the dictionary created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZNBLMFYVuhv",
    "outputId": "c62c7547-1d0e-49e7-c77e-2fb07a711f67"
   },
   "outputs": [],
   "source": [
    "D_T_dict['hereditary retinoblastoma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_TonOcVAG1P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YeNQRLrIYRay"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment Solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
